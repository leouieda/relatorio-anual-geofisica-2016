
@article{amante2009,
  title = {{{ETOPO1}} 1 {{Arc-Minute Global Relief Model}}: {{Procedures}}, {{Data Sources}} and {{Analysis}}},
  shorttitle = {{{ETOPO1}} 1 {{Arc-Minute Global Relief Model}}},
  doi = {10.7289/V5C8276M},
  timestamp = {2015-10-16T19:38:06Z},
  urldate = {2015-08-24},
  journal = {NOAA Technical Memorandum NESDIS NGDC-24. National Geophysical Data Center, NOAA.},
  author = {{Amante}, C and {Eakins}, B. W.},
  year = {2009}
}

@article{asgharzadeh2007,
  title = {Spherical prism gravity effects by {{Gauss-Legendre}} quadrature integration},
  volume = {169},
  issn = {0956540X, 1365246X},
  doi = {10.1111/j.1365-246X.2007.03214.x},
  timestamp = {2013-08-09T17:22:21Z},
  number = {1},
  urldate = {2013-08-09},
  journal = {Geophysical Journal International},
  author = {{Asgharzadeh}, M. F. and {von Frese}, R. R. B. and {Kim}, H. R. and {Leftwich}, T. E. and {Kim}, J. W.},
  month = apr,
  year = {2007},
  pages = {1--11},
  file = {asgharzadeh2007.pdf:/home/leo/Dropbox/artigos/asgharzadeh2007.pdf:application/pdf}
}

@article{assumpcao2013,
  title = {Crustal thickness map of {{Brazil}}: {{Data}} compilation and main features},
  volume = {43},
  issn = {0895-9811},
  shorttitle = {Crustal thickness map of {{Brazil}}},
  doi = {10.1016/j.jsames.2012.12.009},
  abstract = {We present a crustal thickness map of Brazil and adjacent areas based on a compilation of data published in the literature as well as new measurements. We used crustal thicknesses mainly derived from seismic datasets such as deep seismic refraction experiments, receiver function analyses, and surface-wave dispersion velocities. Crustal thicknesses derived from modelling gravity anomalies commonly depend on assumptions, such as constant density contrast across the Moho interface, which are not always easily verifiable and were considered only along the continental shelf to fill large gaps in the seismic data. Our compilation shows that the crust in the stable continental area onshore has an average thickness of 39~\ensuremath{\pm}~5~km (1-\ensuremath{\sigma} deviation) and that no clear difference can be observed between low altitude, intracratonic sedimentary basins, NeoProterozoic foldbelts (except for the Borborema Province), and cratonic areas. The thinnest crust is found in the Borborema Province of NE Brazil (30{\textendash}35~km) and along a narrow belt within Tocantins Province (\ensuremath{\sim}35~km), roughly parallel to the Eastern border of the Amazon craton, while the thickest crust is found in the Amazon and S{\~a}o Francisco cratons (41~\ensuremath{\pm}~4~km), and the Paran{\'a} Basin (42~\ensuremath{\pm}~4~km). Both the Ponta Grossa and the Rio Grande Arches are areas of thinned crust, and the western border of the Brazilian platform, near the sub-Andean region, seems to be characterized by a crustal thickness of less than 40~km. Although sparse in data coverage, we expect the resulting crustal thickness map to be useful for future studies of isostasy, dynamic topography, and crustal evolution of the country.},
  timestamp = {2015-10-26T18:53:49Z},
  urldate = {2014-11-17},
  journal = {Journal of South American Earth Sciences},
  author = {{Assump{\c c}{\~a}o}, Marcelo and {Bianchi}, Marcelo and {Juli{\`a}}, Jordi and {Dias}, F{\'a}bio L. and {Sand Fran{\c c}a}, George and {Nascimento}, Rosana and {Drouet}, St{\'e}phane and {Pav{\~a}o}, C{\'e}sar Garcia and {Albuquerque}, Diogo Farrapo and {Lopes}, Afonso E. V.},
  month = apr,
  year = {2013},
  keywords = {Cratons,Crust,Moho discontinuity,Sedimentary Basins,Seismology},
  pages = {74--85},
  file = {assumpcao2013.pdf:/home/leo/Dropbox/artigos/assumpcao2013.pdf:application/pdf}
}

@article{assumpcao2013a,
  series = {Moho: 100 years after Andrija Mohorovicic},
  title = {Models of crustal thickness for {{South America}} from seismic refraction, receiver functions and surface wave tomography},
  volume = {609},
  issn = {0040-1951},
  doi = {10.1016/j.tecto.2012.11.014},
  abstract = {An extensive compilation of crustal thicknesses is used to develop crustal models in continental South America. We consider point crustal thicknesses from seismic refraction experiments, receiver function analyses, and surface-wave dispersion. Estimates of crustal thickness derived from gravity anomalies were only included along the continental shelf and in some areas of the Andes to fill large gaps in seismic coverage. Two crustal models were developed: A) by simple interpolation of the point estimates, and B) our preferred model, based on the same point estimates, interpolated with surface-wave tomography. Despite gaps in continental coverage, both models reveal interesting crustal thickness variations. In the Andean range, the crust reaches 75 km in Southern Peru and the Bolivian Altiplano, while crustal thicknesses seem to be close to the global continental average ({\textasciitilde} 40 km) in Ecuador and southern Colombia (despite high elevations), and along the southern Andes of Chile{\textendash}Argentina (elevation lower than 2000 m). In the stable continental platform the average thickness is 38 \ensuremath{\pm} 5 km (1-st. deviation) and no systematic differences are observed among Archean{\textendash}Paleoproterozoic cratons, NeoProterozoic fold belts, and low-altitude intracratonic sedimentary basins. An exception is the Borborema Province (NE Brazil) with crust {\textasciitilde} 30{\textendash}35 km thick. Narrow belts surrounding the cratons are suggested in central Brazil, parallel to the eastern and southern border of the Amazon craton, and possibly along the TransBrasiliano Lineament continuing into the Chaco basin, where crust thinner than 35 km is observed. In the sub-Andean region, between the mid-plate cratons and the Andean cordillera, the crust tends to be thinner ({\textasciitilde} 35 km) than the average crust in the stable platform, a feature possibly inherited from the old pre-Cambrian history of the continent. We expect that these crustal models will be useful for studies of isostasy, dynamic topography, and crustal evolution of the continent.},
  timestamp = {2016-02-26T14:16:14Z},
  urldate = {2016-02-26},
  journal = {Tectonophysics},
  author = {{Assump{\c c}{\~a}o}, Marcelo and {Feng}, Mei and {Tassara}, Andr{\'e}s and {Juli{\`a}}, Jordi},
  month = dec,
  year = {2013},
  keywords = {Andes,Crust,Moho,Tomography},
  pages = {82--96},
  file = {assumpcao2013a.pdf:/home/leo/Dropbox/artigos/assumpcao2013a.pdf:application/pdf}
}

@article{bai2014,
  title = {Mapping crustal thickness using marine gravity data: {{Methods}} and uncertainties},
  volume = {79},
  issn = {0016-8033, 1942-2156},
  shorttitle = {Mapping crustal thickness using marine gravity data},
  doi = {10.1190/geo2013-0270.1},
  timestamp = {2015-10-26T18:53:49Z},
  number = {2},
  urldate = {2014-03-11},
  journal = {GEOPHYSICS},
  author = {{Bai}, Yongliang and {Williams}, Simon E. and {M{\"u}ller}, R. Dietmar and {Liu}, Zhan and {Hosseinpour}, Maral},
  month = mar,
  year = {2014},
  pages = {F1--F10},
  file = {bai2014.pdf:/home/leo/Dropbox/artigos/bai2014.pdf:application/pdf}
}

@article{barbosa1999b,
  title = {Stable inversion of gravity anomalies of sedimentary basins with nonsmooth basement reliefs and arbitrary density contrast variations},
  volume = {64},
  issn = {0016-8033},
  doi = {10.1190/1.1444585},
  abstract = {We present a new, stable method for interpreting the basement relief of a sedimentary basin which delineates sharp discontinuities in the basement relief and incorporates any law known a priori for the spatial variation of the density contrast. The subsurface region containing the basin is discretized into a grid of juxtaposed elementary prisms whose density contrasts are the parameters to be estimated. Any vertical line must intersect the basement relief only once, and the mass deficiency must be concentrated near the earth's surface, subject to the observed gravity anomaly being fitted within the experimental errors. In addition, upper and lower bounds on the density contrast of each prism are introduced a priori (one of the bounds being zero), and the method assigns to each elementary prism a density contrast which is close to either bound. The basement relief is therefore delineated by the contact between the prisms with null and nonnull estimated density contrasts, the latter occupying the upper part of the discretized region. The method is stabilized by introducing constraints favoring solutions having the attributes (shared by most sedimentary basins) of being an isolated compact source with lateral borders dipping either vertically or toward the basin center and having horizontal dimensions much greater than its largest vertical dimension. Arbitrary laws of spatial variations of the density contrast, if known a priori, may be incorporated into the problem by assigning suitable values to the nonnull bound of each prism. The proposed method differs from previous stable methods by using no smoothness constraint on the interface to be estimated. As a result, it may be applied not only to intracratonic sag basins where the basement relief is essentially smooth but also to rift basins whose basements present discontinuities caused by faults. The method's utility in mapping such basements was demonstrated in tests using synthetic data produced by simulated rift basins. The method mapped with good precision a sequence of step faults which are close to each other and present small vertical slips, a feature particularly difficult to detect from gravity data only. The method was also able to map isolated discontinuities with large vertical throw. The method was applied to the gravity data from Reco‚ÅÅncavo basin, Brazil. The results showed close agreement with known geological structures of the basin. It also demonstrated the method's ability to map a sequence of alternating terraces and structural lows that could not be detected just by inspecting the gravity anomaly. To demostrate the method's flexibility in incorporating any a priori knowledge about the density contrast variation, it was applied to the Bouguer anomaly over the San Jacinto Graben, California. Two different exponential laws for the decrease of density contrast with depth were used, leading to estimated maximum depths between 2.2 and 2.4 km.},
  timestamp = {2016-02-26T20:15:52Z},
  number = {3},
  urldate = {2016-02-26},
  journal = {GEOPHYSICS},
  author = {{Barbosa}, V. and {Silva}, J. and {Medeiros}, W.},
  month = may,
  year = {1999},
  pages = {754--764},
  file = {barbosa1999b.pdf:/home/leo/Dropbox/artigos/barbosa1999b.pdf:application/pdf}
}

@article{barbosa1999a,
  title = {Gravity inversion of a discontinuous relief stabilized by weighted smoothness constraints on depth},
  volume = {64},
  issn = {0016-8033, 1942-2156},
  doi = {10.1190/1.1444647},
  language = {en},
  timestamp = {2014-03-19T16:17:31Z},
  number = {5},
  urldate = {2014-03-19},
  journal = {GEOPHYSICS},
  author = {{Barbosa}, Val{\'e}ria C. F. and {Silva}, Jo{\~a}o B. C. and {Medeiros}, Walter E.},
  month = sep,
  year = {1999},
  pages = {1429--1437}
}

@article{barnes2012,
  title = {Imaging geologic surfaces by inverting gravity gradient data with depth horizons},
  volume = {77},
  issn = {0016-8033, 1942-2156},
  doi = {10.1190/geo2011-0149.1},
  timestamp = {2013-08-09T17:31:51Z},
  number = {1},
  urldate = {2013-08-09},
  journal = {GEOPHYSICS},
  author = {{Barnes}, Gary and {Barraud}, Joseph},
  month = jan,
  year = {2012},
  pages = {G1--G11},
  file = {barnes2012.pdf:/home/leo/Dropbox/artigos/barnes2012.pdf:application/pdf}
}

@article{barthelmes2012,
  series = {The Geodesists Handbook 2012},
  title = {International {{Centre}} for {{Global Earth Models}} ({{ICGEM}})},
  volume = {86},
  issn = {0949-7714, 1432-1394},
  doi = {10.1007/s00190-012-0584-1},
  language = {en},
  timestamp = {2016-02-26T03:09:44Z},
  number = {10},
  urldate = {2016-02-26},
  journal = {Journal of Geodesy},
  author = {{Barthelmes}, F. and {K{\"o}hler}, W.},
  month = sep,
  year = {2012},
  keywords = {Earth Sciences; general,Geophysics/Geodesy},
  pages = {932--934},
  file = {barthelmes2012.pdf:/home/leo/Dropbox/artigos/barthelmes2012.pdf:application/pdf}
}

@inproceedings{bassin2000,
  series = {F897},
  title = {The {{Current Limits}} of {{Resolution}} for {{Surface Wave Tomography}} in {{North America}}},
  volume = {81},
  timestamp = {2015-10-26T18:53:49Z},
  booktitle = {{{EOS Trans AGU}}},
  author = {{Bassin}, C. and {Laske}, G. and {Masters}, G.},
  year = {2000}
}

@article{bhattacharyya1976,
  title = {A {{Fast Fourier Transform Method}} for {{Rapid Computation}} of {{Gravity}} and {{Magnetic Anomalies Due}} to {{Arbitrary Bodies}}*},
  volume = {24},
  issn = {1365-2478},
  doi = {10.1111/j.1365-2478.1976.tb01562.x},
  abstract = {The spectrum of a magnetic or a gravity anomaly due to a body of a given shape with either homogeneous magnetization or uniform density distribution can be expressed as a product of the Fourier transforms of the source geometry and the Green's function. The transform of the source geometry for any irregularly-shaped body can be accurately determined by representing the body as closely as possible by a number of prismatic bodies. The Green's function is not dependent upon the source geometry. So the analytical expression for its transform remains the same for all causative bodies. It is, therefore, not difficult to obtain the spectrum of an anomaly by multiplying the transform of the source geometry by that of the Green's function. Then the inverse of this spectrum, which yields the anomaly in the space domain, is calculated by using the Fast Fourier Transform algorithm. Many examples show the reliability and accuracy of the method for calculating potential field anomalies.},
  language = {en},
  timestamp = {2015-10-26T18:53:49Z},
  number = {4},
  urldate = {2015-08-08},
  journal = {Geophysical Prospecting},
  author = {{Bhattacharyya}, B. K. and {Navolio}, M. E.},
  month = dec,
  year = {1976},
  pages = {633--649},
  file = {bhattacharyya1976.pdf:/home/leo/Dropbox/artigos/bhattacharyya1976.pdf:application/pdf}
}

@inproceedings{blum1999,
  address = {New York, NY, USA},
  series = {COLT '99},
  title = {Beating the {{Hold}}-out: {{Bounds}} for {{K}}-fold and {{Progressive Cross}}-validation},
  isbn = {978-1-58113-167-3},
  shorttitle = {Beating the {{Hold}}-out},
  doi = {10.1145/307400.307439},
  timestamp = {2015-11-02T13:20:19Z},
  urldate = {2015-11-02},
  booktitle = {Proceedings of the {{Twelfth Annual Conference}} on {{Computational Learning Theory}}},
  publisher = {{ACM}},
  author = {{Blum}, Avrim and {Kalai}, Adam and {Langford}, John},
  year = {1999},
  pages = {203--208},
  file = {blum1999.pdf:/home/leo/Dropbox/artigos/blum1999.pdf:application/pdf}
}

@article{bott1960,
  title = {The use of {{Rapid Digital Computing Methods}} for {{Direct Gravity Interpretation}} of {{Sedimentary Basins}}},
  volume = {3},
  issn = {0956-540X, 1365-246X},
  doi = {10.1111/j.1365-246X.1960.tb00065.x},
  abstract = {A rapid digital computing method for the direct calculation of the shapes of two-dimensional sedimentary basins of known density contrast from their residual gravity anomalies is described. In conclusion an example of the use of the method in determining the shape of the Dumfries New Red Sandstone basin (South Scotland) is given.},
  language = {en},
  timestamp = {2015-11-26T18:49:30Z},
  number = {1},
  urldate = {2015-05-10},
  journal = {Geophysical Journal International},
  author = {{Bott}, M. H. P.},
  month = jan,
  year = {1960},
  pages = {63--67},
  file = {bott1960.pdf:/home/leo/Dropbox/artigos/bott1960.pdf:application/pdf}
}

@article{chulick2013,
  title = {Seismic structure of the crust and uppermost mantle of {{South America}} and surrounding oceanic basins},
  volume = {42},
  issn = {0895-9811},
  doi = {10.1016/j.jsames.2012.06.002},
  abstract = {We present a new set of contour maps of the seismic structure of South America and the surrounding ocean basins. These maps include new data, helping to constrain crustal thickness, whole-crustal average P-wave and S-wave velocity, and the seismic velocity of the uppermost mantle (Pn and Sn). We find that: (1) The weighted average thickness of the crust under South America is 38.17 km (standard deviation, s.d.~\ensuremath{\pm}8.7 km), which is \ensuremath{\sim}1 km thinner than the global average of 39.2 km (s.d. \ensuremath{\pm}8.5 km) for continental crust. (2) Histograms of whole-crustal P-wave velocities for the South American crust are bi-modal, with the lower peak occurring for crust that appears to be missing a high-velocity (6.9{\textendash}7.3 km/s) lower crustal layer. (3) The average P-wave velocity of the crystalline crust (Pcc) is 6.47 km/s (s.d. \ensuremath{\pm}0.25 km/s). This is essentially identical to the global average of 6.45 km/s. (4) The average Pn velocity beneath South America is 8.00 km/s (s.d. \ensuremath{\pm}0.23 km/s), slightly lower than the global average of 8.07 km/s. (5) A region across northern Chile and northeast Argentina has anomalously low P- and S-wave velocities in the crust. Geographically, this corresponds to the shallowly-subducted portion of the Nazca plate (the Pampean flat slab first described by Isacks et~al., 1968), which is also a region of crustal extension. (6) The thick crust of the Brazilian craton appears to extend into Venezuela and Colombia. (7) The crust in the Amazon basin and along the western edge of the Brazilian craton may be thinned by extension. (8) The average crustal P-wave velocity under the eastern Pacific seafloor is higher than under the western Atlantic seafloor, most likely due to the thicker sediment layer on the older Atlantic seafloor.},
  timestamp = {2015-10-26T18:53:49Z},
  urldate = {2015-06-29},
  journal = {Journal of South American Earth Sciences},
  author = {{Chulick}, Gary S. and {Detweiler}, Shane and {Mooney}, Walter D.},
  month = mar,
  year = {2013},
  keywords = {Crustal structure,Seismic velocity,South America},
  pages = {260--276},
  file = {chulick2013.pdf:/home/leo/Dropbox/artigos/chulick2013.pdf:application/pdf}
}

@article{farquharson2004,
  title = {A comparison of automatic techniques for estimating the regularization parameter in non-linear inverse problems},
  volume = {156},
  issn = {0956-540X, 1365-246X},
  doi = {10.1111/j.1365-246X.2004.02190.x},
  abstract = {Two automatic ways of estimating the regularization parameter in underdetermined, minimum-structure-type solutions to non-linear inverse problems are compared: the generalized cross-validation and L-curve criteria. Both criteria provide a means of estimating the regularization parameter when only the relative sizes of the measurement uncertainties in a set of observations are known. The criteria, which are established components of linear inverse theory, are applied to the linearized inverse problem at each iteration in a typical iterative, linearized solution to the non-linear problem. The particular inverse problem considered here is the simultaneous inversion of electromagnetic loop{\textendash}loop data for 1-D models of both electrical conductivity and magnetic susceptibility. The performance of each criteria is illustrated with inversions of a variety of synthetic and field data sets. In the great majority of examples tested, both criteria successfully determined suitable values of the regularization parameter, and hence credible models of the subsurface.},
  language = {en},
  timestamp = {2015-07-29T16:02:20Z},
  number = {3},
  urldate = {2015-07-29},
  journal = {Geophysical Journal International},
  author = {{Farquharson}, Colin G. and {Oldenburg}, Douglas W.},
  month = jan,
  year = {2004},
  keywords = {electromagnetic methods,inversion,regularization},
  pages = {411--425},
  file = {farquharson2004.pdf:/home/leo/Dropbox/artigos/farquharson2004.pdf:application/pdf}
}

@article{gomez-ortiz2005,
  title = {{{3DINVER}}.{{M}}: a {{MATLAB}} program to invert the gravity anomaly over a {{3D}} horizontal density interface by {{Parker{\textendash}Oldenburg}}'s algorithm},
  volume = {31},
  issn = {0098-3004},
  shorttitle = {{{3DINVER}}.{{M}}},
  doi = {10.1016/j.cageo.2004.11.004},
  abstract = {A MATLAB source code 3DINVER.M is described to compute 3D geometry of a horizontal density interface from gridded gravity anomaly by Parker{\textendash}Oldenburg iterative method. This procedure is based on a relationship between the Fourier transform of the gravity anomaly and the sum of the Fourier transform of the interface topography. Given the mean depth of the density interface and the density contrast between the two media, the three-dimensional geometry of the interface is iteratively calculated. The iterative process is terminated when either the RMS error between two successive approximations is lower than a pre-assigned value{\textemdash}used as convergence criterion, or until a pre-assigned maximum number of iterations is reached. A high-cut filter in the frequency domain has been incorporated to enhance the convergence in the iterative process. The algorithm is capable of handling large data sets requiring direct and inverse Fourier transforms effectively. The inversion of a gravity anomaly over Brittany (France) is presented to compute the Moho depth as a practical example.},
  timestamp = {2015-10-26T18:53:49Z},
  number = {4},
  urldate = {2015-06-24},
  journal = {Computers \& Geosciences},
  author = {{G{\'o}mez-Ortiz}, David and {Agarwal}, Bhrigu N. P.},
  month = may,
  year = {2005},
  keywords = {density interface,Fourier transform,MATLAB,Three-dimensional gravity inversion},
  pages = {513--520},
  file = {gomez-ortiz2005.pdf:/home/leo/Dropbox/artigos/gomez-ortiz2005.pdf:application/pdf}
}

@article{grombein2013,
  title = {Optimized formulas for the gravitational field of a tesseroid},
  volume = {87},
  issn = {0949-7714, 1432-1394},
  doi = {10.1007/s00190-013-0636-1},
  abstract = {Various tasks in geodesy, geophysics, and related geosciences require precise information on the impact of mass distributions on gravity field-related quantities, such as the gravitational potential and its partial derivatives. Using forward modeling based on Newton's integral, mass distributions are generally decomposed into regular elementary bodies. In classical approaches, prisms or point mass approximations are mostly utilized. Considering the effect of the sphericity of the Earth, alternative mass modeling methods based on tesseroid bodies (spherical prisms) should be taken into account, particularly in regional and global applications. Expressions for the gravitational field of a point mass are relatively simple when formulated in Cartesian coordinates. In the case of integrating over a tesseroid volume bounded by geocentric spherical coordinates, it will be shown that it is also beneficial to represent the integral kernel in terms of Cartesian coordinates. This considerably simplifies the determination of the tesseroid's potential derivatives in comparison with previously published methodologies that make use of integral kernels expressed in spherical coordinates. Based on this idea, optimized formulas for the gravitational potential of a homogeneous tesseroid and its derivatives up to second-order are elaborated in this paper. These new formulas do not suffer from the polar singularity of the spherical coordinate system and can, therefore, be evaluated for any position on the globe. Since integrals over tesseroid volumes cannot be solved analytically, the numerical evaluation is achieved by means of expanding the integral kernel in a Taylor series with fourth-order error in the spatial coordinates of the integration point. As the structure of the Cartesian integral kernel is substantially simplified, Taylor coefficients can be represented in a compact and computationally attractive form. Thus, the use of the optimized tesseroid formulas particularly benefits from a significant decrease in computation time by about 45 \% compared to previously used algorithms. In order to show the computational efficiency and to validate the mathematical derivations, the new tesseroid formulas are applied to two realistic numerical experiments and are compared to previously published tesseroid methods and the conventional prism approach.},
  language = {en},
  timestamp = {2014-02-18T19:39:18Z},
  number = {7},
  urldate = {2014-02-18},
  journal = {Journal of Geodesy},
  author = {{Grombein}, Thomas and {Seitz}, Kurt and {Heck}, Bernhard},
  month = jul,
  year = {2013},
  keywords = {Earth Sciences; general,Forward modeling,Geophysics/Geodesy,Gravitational field,Newton‚Äôs integral,Tesseroid},
  pages = {645--660},
  file = {grombein2013.pdf:/home/leo/Dropbox/artigos/grombein2013.pdf:application/pdf}
}

@article{hansen1993,
  title = {The {{Use}} of the {{L-Curve}} in the {{Regularization}} of {{Discrete Ill-Posed Problems}}},
  volume = {14},
  issn = {1064-8275},
  doi = {10.1137/0914086},
  abstract = {Regularization algorithms are often used to produce reasonable solutions to ill-posed problems. The L-curve is a plot{\textemdash}for all valid regularization parameters{\textemdash}of the size of the regularized solution versus the size of the corresponding residual. Two main results are established. First a unifying characterization of various regularization methods is given and it is shown that the measurement of {\textquotedblleft}size{\textquotedblright} is dependent on the particular regularization method chosen. For example, the 2-norm is appropriate for Tikhonov regularization, but a 1-norm in the coordinate system of the singular value decomposition (SVD) is relevant to truncated SVD regularization. Second, a new method is proposed for choosing the regularization parameter based on the L-curve, and it is shown how this method can be implemented efficiently. The method is compared to generalized cross validation and this new method is shown to be more robust in the presence of correlated errors.,  Regularization algorithms are often used to produce reasonable solutions to ill-posed problems. The L-curve is a plot{\textemdash}for all valid regularization parameters{\textemdash}of the size of the regularized solution versus the size of the corresponding residual. Two main results are established. First a unifying characterization of various regularization methods is given and it is shown that the measurement of {\textquotedblleft}size{\textquotedblright} is dependent on the particular regularization method chosen. For example, the 2-norm is appropriate for Tikhonov regularization, but a 1-norm in the coordinate system of the singular value decomposition (SVD) is relevant to truncated SVD regularization. Second, a new method is proposed for choosing the regularization parameter based on the L-curve, and it is shown how this method can be implemented efficiently. The method is compared to generalized cross validation and this new method is shown to be more robust in the presence of correlated errors.},
  timestamp = {2014-08-13T13:35:58Z},
  number = {6},
  urldate = {2014-08-13},
  journal = {SIAM Journal on Scientific Computing},
  author = {{Hansen}, P. and {O'Leary}, D.},
  month = nov,
  year = {1993},
  pages = {1487--1503},
  file = {hansen1993.pdf:/home/leo/Dropbox/artigos/hansen1993.pdf:application/pdf}
}

@article{hansen1992,
  title = {Analysis of {{Discrete Ill-Posed Problems}} by {{Means}} of the {{L-Curve}}},
  volume = {34},
  issn = {0036-1445},
  doi = {10.1137/1034115},
  abstract = {When discrete ill-posed problems are analyzed and solved by various numerical regularization techniques, a very convenient way to display information about the regularized solution is to plot the norm or seminorm of the solution versus the norm of the residual vector. In particular, the graph associated with Tikhonov regularization plays a central role. The main purpose of this paper is to advocate the use of this graph in the numerical treatment of discrete ill-posed problems. The graph is characterized quantitatively, and several important relations between regularized solutions and the graph are derived. It is also demonstrated that several methods for choosing the regularization parameter are related to locating a characteristic L-shaped {\textquotedblleft}corner{\textquotedblright} of the graph.},
  timestamp = {2015-11-02T13:53:30Z},
  number = {4},
  urldate = {2015-11-02},
  journal = {SIAM Review},
  author = {{Hansen}, P.},
  month = dec,
  year = {1992},
  pages = {561--580},
  file = {hansen1992.pdf:/home/leo/Dropbox/artigos/hansen1992.pdf:application/pdf}
}

@article{heck2007,
  title = {A comparison of the tesseroid, prism and point-mass approaches for mass reductions in gravity field modelling},
  volume = {81},
  issn = {0949-7714, 1432-1394},
  doi = {10.1007/s00190-006-0094-0},
  abstract = {The calculation of topographic (and iso- static) reductions is one of the most time-consuming operations in gravity field modelling. For this calculation, the topographic surface of the Earth is often divided with respect to geographical or map-grid lines, and the topographic heights are averaged over the respective grid elements. The bodies bounded by surfaces of constant (ellipsoidal) heights and geographical grid lines are denoted as tesseroids. Usually these ellipsoidal (or spherical) tesseroids are replaced by {\textquotedblleft}equivalent{\textquotedblright} vertical rectangular prisms of the same mass. This approximation is motivated by the fact that the volume integrals for the calculation of the potential and its derivatives can be exactly solved for rectangular prisms, but not for the tesseroids. In this paper, an approximate solution of the spherical tesseroid integrals is provided based on series expansions including third-order terms. By choosing the geometrical centre of the tesseroid as the Taylor expansion point, the number of non-vanishing series terms can be greatly reduced. The zero-order term is equivalent to the point-mass formula. Test computations show the high numerical efficiency of the tesseroid method versus the prism approach, both regarding computation time and accuracy. Since the approximation errors due to the truncation of the Taylor series decrease very quickly with increasing distance of the tesseroid from the computation point, only the elements in the direct vicinity of the computation point have to be separately evaluated, e.g. by the prism formulas. The results are also compared with the point-mass formula. Further potential refinements of the tesseroid approach, such as considering ellipsoidal tesseroids, are indicated.},
  language = {en},
  timestamp = {2014-03-19T17:07:45Z},
  number = {2},
  urldate = {2014-03-19},
  journal = {Journal of Geodesy},
  author = {{Heck}, B. and {Seitz}, K.},
  month = feb,
  year = {2007},
  keywords = {Geophysics/Geodesy,Math. Applications in Geosciences,Newton‚Äôs integral,Point-mass modelling,Prism method,Tesseroid,Topographic reduction},
  pages = {121--136},
  file = {heck2007.pdf:/home/leo/Dropbox/artigos/heck2007.pdf:application/pdf}
}

@article{heintz2005,
  title = {Upper mantle structure of the {{South American}} continent and neighboring oceans from surface wave tomography},
  volume = {406},
  issn = {0040-1951},
  doi = {10.1016/j.tecto.2005.05.006},
  abstract = {We present a new three-dimensional SV-wave velocity model for the upper mantle beneath South America and the surrounding oceans, built from the waveform inversion of 5850 Rayleigh wave seismograms. The dense path coverage and the use of higher modes to supplement the fundamental mode of surface waves allow us to constrain seismic heterogeneities with horizontal wavelengths of a few hundred kilometres in the uppermost 400 km of the mantle.

The large scale features of our tomographic model confirm previous results from global and regional tomographic studies (e.g. the depth extent of the high velocity cratonic roots down to about 200{\textendash}250 km).

Several new features are highlighted in our model. Down to 100 km depth, the high velocity lid beneath the Amazonian craton is separated in two parts associated with the Guyana and Guapore shields, suggesting that the rifting episode responsible for the formation of the Amazon basin has involved a significant part of the lithosphere. Along the Andean subduction belt, the structure of the high velocity anomaly associated with the sudbduction of the Nazca plate beneath the South American plate reflects the along-strike variation in dip of the subducting plate. Slow velocities are observed down to about 100 km and 150 km at the intersection of the Carnegie and Chile ridges with the continent and are likely to represent the thermal anomalies associated with the subducted ridges. These lowered velocities might correspond to zones of weakness in the subducted plate and may have led to the formation of {\textquotedblleft}slab windows{\textquotedblright} developed through unzipping of the subducted ridges; these windows might accommodate a transfer of asthenospheric mantle from the Pacific to the Atlantic ocean. From 150 to 250 km depth, the subducting Nazca plate is associated with high seismic velocities between 5{\textdegree}S and 37{\textdegree}S. We find high seismic velocities beneath the Paran{\'a} basin down to about 200 km depth, underlain by a low velocity anomaly in the depth range 200{\textendash}400 km located beneath the Ponta Grossa arc at the southern tip of the basin. This high velocity anomaly is located southward of a narrow S-wave low velocity structure observed between 200 and 500{\textendash}600 km depth in body wave studies, but irresolvable with our long period datasets. Both anomalies point to a model in which several, possibly diachronous, plumes have risen to the surface to generate the Paran{\'a} large igneous province (LIP).},
  timestamp = {2015-10-26T18:53:49Z},
  number = {1{\textendash}2},
  urldate = {2015-06-29},
  journal = {Tectonophysics},
  author = {{Heintz}, Maggy and {Debayle}, Eric and {Vauchez}, Alain},
  month = aug,
  year = {2005},
  keywords = {Cratonic roots,South American continent,Subduction,Surface wave higher modes,Tomography,upper mantle},
  pages = {115--139},
  file = {heintz2005.pdf:/home/leo/Dropbox/artigos/heintz2005.pdf:application/pdf}
}

@article{hunter2007,
  title = {Matplotlib: {{A 2D}} graphics environment},
  volume = {9},
  shorttitle = {Matplotlib},
  doi = {10.1109/MCSE.2007.55},
  timestamp = {2015-10-26T18:53:49Z},
  number = {3},
  urldate = {2013-10-22},
  journal = {Computing in Science \& Engineering},
  author = {{Hunter}, John D.},
  year = {2007},
  pages = {90--95},
  file = {hunter2007.pdf:/home/leo/Dropbox/artigos/hunter2007.pdf:application/pdf}
}

@misc{jones2001,
  title = {{{SciPy}}: {{Open}} source scientific tools for {{Python}}},
  timestamp = {2016-02-26T03:12:50Z},
  howpublished = {\url{http://www.scipy.org/}},
  author = {{Jones}, Eric and {Oliphant}, Travis and {Peterson}, Pearu and {others}},
  year = {2001},
  note = {Accessed 22-08-2015}
}

@book{kelley1987,
  address = {Philadelphia},
  edition = {1 edition},
  title = {Iterative {{Methods}} for {{Optimization}}},
  isbn = {978-0-89871-433-3},
  language = {English},
  timestamp = {2015-10-26T18:53:49Z},
  publisher = {{Society for Industrial and Applied Mathematics}},
  author = {{Kelley}, C. T.},
  month = jan,
  year = {1987},
  file = {kelley1987.pdf:/home/leo/Dropbox/artigos/kelley1987.pdf:application/pdf}
}

@article{kim2009,
  title = {Estimating classification error rate: {{Repeated}} cross-validation, repeated hold-out and bootstrap},
  volume = {53},
  issn = {0167-9473},
  shorttitle = {Estimating classification error rate},
  doi = {10.1016/j.csda.2009.04.009},
  abstract = {We consider the accuracy estimation of a classifier constructed on a given training sample. The naive resubstitution estimate is known to have a downward bias problem. The traditional approach to tackling this bias problem is cross-validation. The bootstrap is another way to bring down the high variability of cross-validation. But a direct comparison of the two estimators, cross-validation and bootstrap, is not fair because the latter estimator requires much heavier computation. We performed an empirical study to compare the~.632+~bootstrap estimator with the repeated 10-fold cross-validation and the repeated one-third holdout estimator. All the estimators were set to require about the same amount of computation. In the simulation study, the repeated 10-fold cross-validation estimator was found to have better performance than the~.632+~bootstrap estimator when the classifier is highly adaptive to the training sample. We have also found that the~.632+~bootstrap estimator suffers from a bias problem for large samples as well as for small samples.},
  timestamp = {2015-11-02T13:18:09Z},
  number = {11},
  urldate = {2015-11-02},
  journal = {Computational Statistics \& Data Analysis},
  author = {{Kim}, Ji-Hyun},
  month = sep,
  year = {2009},
  pages = {3735--3745},
  file = {kim2009.pdf:/home/leo/Dropbox/artigos/kim2009.pdf:application/pdf}
}

@article{kruger2002,
  title = {Crustal and upper mantle structure in the {{Amazon}} region ({{Brazil}}) determined with broadband mobile stations},
  volume = {107},
  issn = {2156-2202},
  doi = {10.1029/2001JB000598},
  abstract = {Three broadband stations operated from March 1997 to September 1998 in the Amazon region north of Manaus, Brazil, which, including the IRIS station PTGA (Pitinga), covered an area of roughly 60 {\texttimes} 200 km. Applying the receiver function technique to determine the crustal structure, there is evidence for an increase of the Moho depth from about 38 km below the Amazon Basin to approximately 48 km north of the basin. In addition, we analyzed the polarization of SKS-waves to determine anisotropy. The observed splitting parameters in a majority of the data set can be accounted for by a layer of axial symmetric anisotropy with the fast direction oriented roughly N110E. This direction cannot be associated with the present-day plate motion of the South American plate. However, the anisotropy may be related to a lithospheric fabric that was generated during the early tectonic history of the Amazonian Craton.},
  language = {en},
  timestamp = {2016-02-24T22:20:16Z},
  number = {B10},
  urldate = {2016-02-24},
  journal = {Journal of Geophysical Research: Solid Earth},
  author = {{Kr{\"u}ger}, F. and {Scherbaum}, F. and {Rosa}, J. W. C. and {Kind}, R. and {Zetsche}, F. and {H{\"o}hne}, J.},
  month = oct,
  year = {2002},
  keywords = {7203 Body waves,7205 Continental crust,7208 Mantle,7218 Lithosphere,8121 Tectonophysics: Dynamics; convection currents and mantle plumes,8123 Tectonophysics: Dynamics; seismotectonics},
  pages = {2265},
  file = {kruger2002.pdf:/home/leo/Dropbox/artigos/kruger2002.pdf:application/pdf}
}

@inproceedings{laske2013,
  title = {Update on {{CRUST1}}.0 - {{A}} 1-degree {{Global Model}} of {{Earth}}'s {{Crust}}},
  volume = {15},
  timestamp = {2016-02-24T19:27:40Z},
  booktitle = {{{EGU General Assembly Conference Abstracts}}},
  author = {{Laske}, G. and {Masters}, G. and {Ma}, Z. and {Pasyanos}, M.},
  year = {2013},
  pages = {EGU2013--2658},
  file = {laske2013.pdf:/home/leo/Dropbox/artigos/laske2013.pdf:application/pdf}
}

@article{leao1996,
  title = {Gravity inversion of basement relief constrained by the knowledge of depth at isolated points},
  volume = {61},
  issn = {0016-8033},
  doi = {10.1190/1.1444088},
  abstract = {We present an interpretation method for the gravity anomaly of an arbitrary interface separating two homogeneous media. It consists essentially of a downward continuation of the observed anomaly and the division of the continued anomaly by a scale factor involving the density contrast between the media. The knowledge of the interface depth at isolated points is used to estimate the depth d1\ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}d\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}1\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>} of the shallowest point of the interface, the density contrast \ensuremath{{\Delta}{\rho}} between the two media, and the coefficients \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}c\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}1\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>} and \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}c\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}2\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>} of a first-order polynomial representing a linear trend to be removed from data. The solutions are stabilized by introducing a damping parameter in the computation of the downward-continued anomaly by the equivalent layer method. Different from other interface mapping methods using gravity data, the proposed method: (1) takes into account the presence of an undesirable linear trend in data; (2) requires just intervals for both \ensuremath{{\Delta}{\rho}} (rather than the knowledge of its true value) and coefficients \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}c\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}1\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>} and \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}c\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}2\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>}; and (3) does not require the knowledge of the average interface depth \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}z\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}0\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>}. As a result of (3), the proposed method does not call for extensive knowledge of the interface depth to obtain a statistically significant estimate of \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}z\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}0\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>}; rather, it is able to use the knowledge of the interface depth at just a few isolated points to estimate \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}d\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}1\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>}, \ensuremath{{\Delta}{\rho}}, \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}c\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}1\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>}, and \ensuremath{<}math overflow="scroll"\ensuremath{><}mrow\ensuremath{><}msub\ensuremath{><}mi\ensuremath{>}c\ensuremath{<}/mi\ensuremath{><}mrow\ensuremath{><}mn\ensuremath{>}2\ensuremath{<}/mn\ensuremath{><}/mrow\ensuremath{><}/msub\ensuremath{><}/mrow\ensuremath{><}/math\ensuremath{>}. Tests using synthetic data confirm that the method produces good and stable estimates as far as the established premises (smooth interface separating two homogeneous media and, at most, the presence of an unremoved linear trend in data) are not violated. If the density contrast is not uniform, the method may still be applied using Litinsky's concept of effective density. The method was applied to gravity data from Rec{\^o}ncavo Basin, Brazil, producing good correlations of estimated lows and terraces in the basement with corresponding known geological features.},
  timestamp = {2015-01-15T16:04:51Z},
  number = {6},
  urldate = {2015-01-15},
  journal = {GEOPHYSICS},
  author = {{Le{\~a}o}, J. and {Menezes}, P. and {Beltr{\~a}o}, J. and {Silva}, J.},
  month = nov,
  year = {1996},
  pages = {1702--1714},
  file = {leao1996.pdf:/home/leo/Dropbox/artigos/leao1996.pdf:application/pdf}
}

@article{li2001a,
  title = {Ellipsoid, geoid, gravity, geodesy, and geophysics},
  volume = {66},
  issn = {0016-8033},
  doi = {10.1190/1.1487109},
  abstract = {Geophysics uses gravity to learn about the density variations of the Earth's interior, whereas classical geodesy uses gravity to define the geoid. This difference in purpose has led to some confusion among geophysicists, and this tutorial attempts to clarify two points of the confusion. First, it is well known now that gravity anomalies after the {\textquotedblleft}free-air{\textquotedblright} correction are still located at their original positions. However, the {\textquotedblleft}free-air{\textquotedblright} reduction was thought historically to relocate gravity from its observation position to the geoid (mean sea level). Such an understanding is a geodetic fiction, invalid and unacceptable in geophysics. Second, in gravity corrections and gravity anomalies, the elevation has been used routinely. The main reason is that, before the emergence and widespread use of the Global Positioning System (GPS), height above the geoid was the only height measurement we could make accurately (i.e., by leveling). The GPS delivers a measurement of height above the ellipsoid. In principle, in the geophysical use of gravity, the ellipsoid height rather than the elevation should be used throughout because a combination of the latitude correction estimated by the International Gravity Formula and the height correction is designed to remove the gravity effects due to an ellipsoid of revolution. In practice, for minerals and petroleum exploration, use of the elevation rather than the ellipsoid height hardly introduces significant errors across the region of investigation because the geoid is very smooth. Furthermore, the gravity effects due to an ellipsoid actually can be calculated by a closed-form expression. However, its approximation, by the International Gravity Formula and the height correction including the second-order terms, is typically accurate enough worldwide.},
  timestamp = {2015-10-26T18:53:49Z},
  number = {6},
  urldate = {2014-10-01},
  journal = {GEOPHYSICS},
  author = {{Li}, X. and {G{\"o}tze}, H.},
  month = nov,
  year = {2001},
  pages = {1660--1668},
  file = {li2001a.pdf:/home/leo/Dropbox/artigos/li2001a.pdf:application/pdf}
}

@article{li2011,
  title = {An efficient and adaptive approach for modeling gravity effects in spherical coordinates},
  volume = {73},
  issn = {09269851},
  doi = {10.1016/j.jappgeo.2011.01.004},
  timestamp = {2013-09-18T15:45:51Z},
  number = {3},
  urldate = {2013-09-18},
  journal = {Journal of Applied Geophysics},
  author = {{Li}, Zhiwei and {Hao}, Tianyao and {Xu}, Ya and {Xu}, Yi},
  month = mar,
  year = {2011},
  pages = {221--231},
  file = {li2011.pdf:/home/leo/Dropbox/artigos/li2011.pdf:application/pdf}
}

@article{mariani2013,
  title = {Explaining the thick crust in {{Paran{\'a}}} basin, {{Brazil}}, with satellite {{GOCE}} gravity observations},
  volume = {45},
  issn = {08959811},
  doi = {10.1016/j.jsames.2013.03.008},
  timestamp = {2013-09-16T16:03:52Z},
  urldate = {2013-09-16},
  journal = {Journal of South American Earth Sciences},
  author = {{Mariani}, Patrizia and {Braitenberg}, Carla and {Ussami}, Naomi},
  month = aug,
  year = {2013},
  pages = {209--223},
  file = {mariani2013.pdf:/home/leo/Dropbox/artigos/mariani2013.pdf:application/pdf}
}

@article{martins2010,
  title = {Simultaneous {{3D}} depth-to-basement and density-contrast estimates using gravity data and depth control at few points},
  volume = {75},
  issn = {0016-8033},
  doi = {10.1190/1.3380225},
  abstract = {We have developed a gravity-inversion method for simultaneously estimating the 3D basement relief of a sedimentary basin and the parameters defining a presumed parabolic decay of the density contrast with depth in a sedimentary pack, assuming prior knowledge about the basement depth at a few points. The sedimentary pack is approximated by a grid of 3D vertical prisms juxtaposed in both horizontal directions of a right-handed coordinate system. The prisms' thicknesses represent the depths to the basement and are the parameters to be estimated from the gravity data. To estimate the parameters defining the parabolic decay of the density contrast with depth and to produce stable depth-to-basement estimates, we imposed smoothness on the basement depths and proximity between estimated and known depths at boreholes. We applied our method to synthetic data from a simulated complex 3D basement relief with two sedimentary sections having distinct parabolic laws describing the density-contrast variation with depth. The results provide good estimates of the true parameters of the parabolic law of density-contrast decay with depth and of the basement relief. Inverting the gravity data from the onshore and part of the shallow offshore Almada Basin on Brazil's northeastern coast shows good correlation with known structural features.},
  timestamp = {2014-12-18T18:07:39Z},
  number = {3},
  urldate = {2014-12-18},
  journal = {GEOPHYSICS},
  author = {{Martins}, C. and {Barbosa}, V. and {Silva}, J.},
  month = may,
  year = {2010},
  pages = {I21--I28},
  file = {martins2010.pdf:/home/leo/Dropbox/artigos/martins2010.pdf:application/pdf}
}

@article{martins2011,
  title = {Total variation regularization for depth-to-basement estimate: {{Part}} 1 {\textemdash} {{Mathematical}} details and applications},
  volume = {76},
  issn = {0016-8033},
  shorttitle = {Total variation regularization for depth-to-basement estimate},
  doi = {10.1190/1.3524286},
  abstract = {We have developed an inversion approach that estimates the basement relief of a fault-bounded sedimentary basin. The sedimentary pack is approximated by a grid of 3D or 2D vertical prisms juxtaposed in the horizontal directions of a right-handed coordinate system. The prisms' thicknesses represent the depths to the basement and are the parameters to be estimated from the gravity data. To obtain depth-to-basement estimates, we introduce the total variation (TV) regularization as a stabilizing function. This approach lets us estimate a nonsmooth basement relief because it does not penalize sharp features of the solution. We have deduced a compact matrix form of the gradient vector and the Hessian matrix of the approximation to the TV function that allows a regularized Gauss-Newton minimization approach. Because the Hessian matrix of the approximation to the TV function is ill conditioned, we have modified this Hessian matrix to improve its condition and to accelerate the convergence of the Gauss-Newton algorithm. Tests conducted with synthetic data show that the inversion method can delineate discontinuous basements presenting large slips or sequences of small-slip step faults. Tests on field data from the Almada Basin, Brazil, and from the San Jacinto Graben, California, U.S.A., confirm the potential of the method in detecting and locating in-depth normal faults in the basement relief of a sedimentary basin.},
  timestamp = {2014-12-18T18:02:41Z},
  number = {1},
  urldate = {2014-12-18},
  journal = {GEOPHYSICS},
  author = {{Martins}, C. and {Lima}, W. and {Barbosa}, V. and {Silva}, J.},
  month = jan,
  year = {2011},
  pages = {I1--I12},
  file = {martins2011.pdf:/home/leo/Dropbox/artigos/martins2011.pdf:application/pdf}
}

@inproceedings{mayer-guerr2015,
  title = {The combined satellite gravity field model {{GOCO05s}}},
  volume = {17},
  abstract = {The main objective of the GOCO ("Gravity Observation Combination") project is to compute high-accuracy and high-resolution static global gravity field models based on data of the dedicated satellite gravity missions CHAMP, GRACE, and GOCE, SLR data and kinematic orbits from different Low Earth Orbiters. For the computation of the new model GOCO05s more than 800,000,000 observations from 15 satellites are used to estimate about 122,000 gravity field parameters. GOCO05s consists not only of a static field up to degree and order 200, but the temporal variations of the gravity field are modeled as well. These are
represented as regularized trend and annual signal. The main focus in the GOCO combination process is on the proper handling of the stochastic behavior of the data. Therefore, the resulting accuracy information in terms of a full variance covariance matrix is quite realistic and also published with the solution.},
  timestamp = {2016-02-24T19:27:14Z},
  urldate = {2016-02-24},
  booktitle = {{{EGU General Assembly Conference Abstracts}}},
  author = {{Mayer-Guerr}, Torsten and {Pail}, R. and {Gruber}, T. and {Fecher}, T. and {Rexer}, M. and {Schuh}, W. D. and {Kusche}, J. and {Brockmann}, J. M. and {Rieser}, D. and {Zehentner}, N. and {Kvas}, A. and {Klinger}, B. and {Baur}, O. and {H{\"o}ck}, E. and {Krauss}, S. and {J{\"a}ggi}, A.},
  month = apr,
  year = {2015},
  pages = {EGU2015--12364},
  file = {mayer-guerr2015.pdf:/home/leo/Dropbox/artigos/mayer-guerr2015.pdf:application/pdf}
}

@article{nunn1988,
  title = {Gravity anomalies and flexure of the lithosphere at the {{Middle Amazon Basin}}, {{Brazil}}},
  volume = {93},
  issn = {0148-0227},
  doi = {10.1029/JB093iB01p00415},
  language = {en},
  timestamp = {2016-02-24T22:08:29Z},
  number = {B1},
  urldate = {2016-02-24},
  journal = {Journal of Geophysical Research},
  author = {{Nunn}, Jeffrey A. and {Aires}, Jose R.},
  year = {1988},
  pages = {415},
  file = {nunn1988.pdf:/home/leo/Dropbox/artigos/nunn1988.pdf:application/pdf}
}

@article{oldenburg1974,
  title = {The inversion and interpretation of gravity anomalies},
  volume = {39},
  issn = {0016-8033},
  doi = {10.1190/1.1440444},
  abstract = {A rearrangement of the formula used for the rapid calculation of the gravitational anomaly caused by a two-dimensional uneven layer of material (Parker, 1972) leads to an iterative procedure for calculating the shape of the perturbing body given the anomaly. The method readily handles large numbers of model points, and it is found empirically that convergence of the iteration can be assured by application of a low-pass filter. The nonuniqueness of the inversion can be characterized by two free parameters: the assumed density contrast between the two media, and the level at which the inverted topography is calculated. Additional geophysical knowledge is required to reduce this ambiguity. The inversion of a gravity profile perpendicular to a continental margin to find the location of the Moho is offered as a practical example of this method.},
  timestamp = {2016-02-26T20:11:04Z},
  number = {4},
  urldate = {2016-02-26},
  journal = {GEOPHYSICS},
  author = {{Oldenburg}, D.},
  month = aug,
  year = {1974},
  pages = {526--536},
  file = {oldenburg1974.pdf:/home/leo/Dropbox/artigos/oldenburg1974.pdf:application/pdf}
}

@article{parker1973,
  title = {The {{Rapid Calculation}} of {{Potential Anomalies}}},
  volume = {31},
  issn = {0956-540X, 1365-246X},
  doi = {10.1111/j.1365-246X.1973.tb06513.x},
  abstract = {It is shown how a series of Fourier transforms can be used to calculate the magnetic or gravitational anomaly caused by an uneven, non-uniform layer of material. Modern methods for finding Fourier transforms numerically are very fast and make this approach attractive in situations where large quantities of observations are available.},
  language = {en},
  timestamp = {2016-02-26T20:41:29Z},
  number = {4},
  urldate = {2016-02-26},
  journal = {Geophysical Journal International},
  author = {{Parker}, R. L.},
  month = jan,
  year = {1973},
  pages = {447--455},
  file = {parker1973.pdf:/home/leo/Dropbox/artigos/parker1973.pdf:application/pdf}
}

@article{perez2007,
  title = {{{IPython}}: {{A System}} for {{Interactive Scientific Computing}}},
  volume = {9},
  issn = {1521-9615},
  shorttitle = {{{IPython}}},
  doi = {10.1109/MCSE.2007.53},
  abstract = {Python offers basic facilities for interactive work and a comprehensive library on top of which more sophisticated systems can be built. The IPython project provides an enhanced interactive environment that includes, among other features, support for data visualization and facilities for distributed and parallel computation.},
  timestamp = {2015-10-26T18:53:49Z},
  number = {3},
  urldate = {2014-11-18},
  journal = {Computing in Science \& Engineering},
  author = {{P{\'e}rez}, Fernando and {Granger}, Brian E.},
  month = may,
  year = {2007},
  keywords = {Data visualization},
  pages = {21--29},
  file = {perez2007.pdf:/home/leo/Dropbox/artigos/perez2007.pdf:application/pdf}
}

@article{pilkington2008,
  title = {{{3D}} magnetic data-space inversion with sparseness constraints},
  volume = {74},
  issn = {0016-8033},
  doi = {10.1190/1.3026538},
  abstract = {I have developed an inversion approach that determines a 3D susceptibility distribution that produces a given magnetic anomaly. The subsurface model consists of a 3D, equally spaced array of dipoles. The inversion incorporates a model norm that enforces sparseness and depth weighting of the solution. Sparseness is imposed by using the Cauchy norm on model parameters. The inverse problem is posed in the data space, leading to a linear system of equations with dimensions based on the number of data,  NN\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{><}mi\ensuremath{>}N\ensuremath{<}/mi\ensuremath{><}/math\ensuremath{>} . This contrasts with the standard least-squares solution, derived through operations within the  MM\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{><}mi\ensuremath{>}M\ensuremath{<}/mi\ensuremath{><}/math\ensuremath{>} -dimensional model space ( MM\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{><}mi\ensuremath{>}M\ensuremath{<}/mi\ensuremath{><}/math\ensuremath{>}  being the number of model parameters). Hence, the data-space method combined with a conjugate gradient algorithm leads to computational efficiency by dealing with an  N{\texttimes}NN{\texttimes}N\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{>} \ensuremath{<}mrow\ensuremath{><}mi\ensuremath{>}N\ensuremath{<}/mi\ensuremath{><}mo\ensuremath{>}{\texttimes}\ensuremath{<}/mo\ensuremath{><}mi\ensuremath{>}N\ensuremath{<}/mi\ensuremath{><}/mrow\ensuremath{>} \ensuremath{<}/math\ensuremath{>}  system versus an  M{\texttimes}MM{\texttimes}M\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{>} \ensuremath{<}mrow\ensuremath{><}mi\ensuremath{>}M\ensuremath{<}/mi\ensuremath{><}mo\ensuremath{>}{\texttimes}\ensuremath{<}/mo\ensuremath{><}mi\ensuremath{>}M\ensuremath{<}/mi\ensuremath{><}/mrow\ensuremath{>} \ensuremath{<}/math\ensuremath{>}  one, where  N\ensuremath{\ll}MN\ensuremath{\ll}M\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{>} \ensuremath{<}mrow\ensuremath{><}mi\ensuremath{>}N\ensuremath{<}/mi\ensuremath{><}mo\ensuremath{>{\ll}<}/mo\ensuremath{><}mi\ensuremath{>}M\ensuremath{<}/mi\ensuremath{><}/mrow\ensuremath{>} \ensuremath{<}/math\ensuremath{>} . Tests on synthetic data show that sparse inversion produces a much more focused solution compared with a standard model-space, least-squares inversion. The inversion of aeromagnetic data collected over a Precambrian Shield area again shows that including the sparseness constraint leads to a simpler and better resolved solution. The degree of improvement in model resolution for the sparse case is quantified using the resolution matrix.},
  timestamp = {2016-02-26T15:18:57Z},
  number = {1},
  urldate = {2016-02-26},
  journal = {GEOPHYSICS},
  author = {{Pilkington}, M.},
  month = dec,
  year = {2008},
  pages = {L7--L15},
  file = {pilkington2008.pdf:/home/leo/Dropbox/artigos/pilkington2008.pdf:application/pdf}
}

@article{reguzzoni2013,
  title = {Global {{Moho}} from the combination of the {{CRUST2}}.0 model and {{GOCE}} data},
  issn = {0956-540X, 1365-246X},
  doi = {10.1093/gji/ggt247},
  timestamp = {2015-10-26T18:53:49Z},
  urldate = {2013-09-09},
  journal = {Geophysical Journal International},
  author = {{Reguzzoni}, M. and {Sampietro}, D. and {Sanso}, F.},
  month = jul,
  year = {2013},
  file = {reguzzoni2013.pdf:/home/leo/Dropbox/artigos/reguzzoni2013.pdf:application/pdf}
}

@article{sacchi1996,
  title = {Estimation of the discrete {{Fourier}} transform, a linear inversion approach},
  volume = {61},
  timestamp = {2013-08-09T16:55:54Z},
  number = {4},
  urldate = {2013-08-09},
  journal = {Geophysics},
  author = {{Sacchi}, Mauricio D. and {Ulrych}, Tadeusz J.},
  year = {1996},
  pages = {1128--1136},
  file = {sacchi1996.pdf:/home/leo/Dropbox/artigos/sacchi1996.pdf:application/pdf}
}

@article{santos2015,
  title = {Efficient gravity inversion of discontinuous basement relief},
  issn = {0016-8033},
  doi = {10.1190/geo2014-0513.1},
  abstract = {We have developed a gravity inversion method to estimate a discontinuous basement relief based on an extended version of Bott's method that allows variable density contrasts between sediments and basement, optimizes the modulus of the solution correction at each iteration, and provides for solution stabilization. Initially, we obtain a linear approximation stabilized by the total variation functional that correctly maps the horizontal positions of the existing high-angle faults but produced poor estimates of the basin depths. Subsequent iterations update the depth estimates toward the correct values, at the same time preserving the correct fault horizontal positions. Additionally, we stabilize each solution correction by the smoothness constraint without inverting any matrix. The method was substantially more efficient than the nonlinear method, which solves a system of linear equations by the conjugate gradient method at each iteration. For 3000 parameters, it is almost four times faster than the conjugate gradient, and this ratio increased with the number of parameters.},
  timestamp = {2015-10-26T18:53:49Z},
  urldate = {2015-05-07},
  journal = {GEOPHYSICS},
  author = {{Santos}, D. and {Silva}, J. and {Martins}, C. and {dos Santos}, R. and {Ramos}, L. and {de Ara{\'u}jo}, A.},
  month = may,
  year = {2015},
  pages = {G95--G106},
  file = {santos2015.pdf:/home/leo/Dropbox/artigos/santos2015.pdf:application/pdf}
}

@article{silva2006,
  title = {Gravity inversion of basement relief and estimation of density contrast variation with depth},
  volume = {71},
  issn = {0016-8033},
  doi = {10.1190/1.2236383},
  abstract = {We present a method to estimate the basement relief as well as the density contrast at the surface and the hyperbolic decaying factor of the density contrast with depth, assuming that the gravity anomaly and the depth to the basement at a few points are known. In both cases, the interpretation model is a set of vertical rectangular 2D prisms whose thicknesses are parameters to be estimated and that represent the depth to the interface separating sediments and basement. The solutions to both problems are stable because of the incorporation of additional prior information about the smoothness of the estimated relief and the depth to the basement at a few locations, presumably provided by boreholes. The method was tested with synthetic gravity anomalies produced by simulated sedimentary basins with smooth relief, providing not only well-resolved estimated relief, but also good estimates for the density contrasts at the surface and for the decaying factors of the density contrast with depth. The method was applied to the Bouguer anomaly from Rec{\^o}ncavo Basin, estimating the surface density contrast and the decaying factor of the density contrast with depth as  -0.30g/cm3\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{>} \ensuremath{<}mrow\ensuremath{><}mo\ensuremath{>}-\ensuremath{<}/mo\ensuremath{><}mn\ensuremath{>}0.30\ensuremath{<}/mn\ensuremath{>} \ensuremath{<}mspace width="0.3em"\ensuremath{><}/mspace\ensuremath{><}mi mathvariant="normal"\ensuremath{>}g\ensuremath{<}/mi\ensuremath{><}mo\ensuremath{>}‚àï\ensuremath{<}/mo\ensuremath{>} \ensuremath{<}msup\ensuremath{><}mi\ensuremath{>}cm\ensuremath{<}/mi\ensuremath{><}mn\ensuremath{>}3\ensuremath{<}/mn\ensuremath{><}/msup\ensuremath{>} \ensuremath{<}/mrow\ensuremath{>} \ensuremath{<}/math\ensuremath{>}  and  30km\ensuremath{<}math overflow="scroll" display="inline"\ensuremath{>} \ensuremath{<}mrow\ensuremath{><}mn\ensuremath{>}30\ensuremath{<}/mn\ensuremath{>} \ensuremath{<}mspace width="0.3em"\ensuremath{><}/mspace\ensuremath{><}mi\ensuremath{>}km\ensuremath{<}/mi\ensuremath{><}/mrow\ensuremath{>} \ensuremath{<}/math\ensuremath{>} , respectively.},
  timestamp = {2015-01-27T16:00:20Z},
  number = {5},
  urldate = {2015-01-27},
  journal = {GEOPHYSICS},
  author = {{Silva}, J. and {Costa}, D. and {Barbosa}, V.},
  month = sep,
  year = {2006},
  pages = {J51--J58},
  file = {silva2006.pdf:/home/leo/Dropbox/artigos/silva2006.pdf:application/pdf}
}

@article{silva2001b,
  title = {Potential-field inversion: {{Choosing}} the appropriate technique to solve a geologic problem},
  volume = {66},
  issn = {0016-8033},
  shorttitle = {Potential-field inversion},
  doi = {10.1190/1.1444941},
  abstract = {To produce a unique and stable solution in potential-field interpretation, an inversion method must introduce particular constraints. These constraints will inevitably restrict the type of geological setting where the method may be applied. We present a nonmathematical overview of most stabilizing constraints used in inversion methods. Our purpose is to demonstrate that the inversion results are valuable only if the mathematical stabilizing constraints are translated from the geological setting. We identify five basic types of constraints: (1) lower and upper bounds of parameter estimates; (2) proximity of a parameter estimate to a specified value; (3) proximity between pairs of parameter estimates; (4) concentration of the anomalous source about a geometrical element such as an axis; and (5) source compactness. In practice, if used in isolation, constraints (1), (2), (4), and (5) will not produce geologically meaningful results, regardless of the geological setting of the interpretation area. Constraint (3) may produce geologically meaningful results if the anomalous source has a spatially smooth attribute such as the physical property. We illustrate that constraints 1{\textendash}4, if used in isolation, cannot delineate the geometry of a simulated sill intruded into a sedimentary basin. The basic constraints may (and should) be combined in inversion to produce geologically meaningful results. We present two examples of effective constraint combination: (1) proximity to a specific value and mass concentration about an axis (used to delineate the thickness variation of a sill intruded in a sedimentary basin) and (2) inequality, proximity of a parameter estimate to a specified value, and proximity between pairs of parameter estimates (used to map a discontinuous basement relief). Usually, the stabilizing constraints are too restrictive to hold at all points of a given geological environment. In this case, we use different constraints in different sub-areas. Each constraint is based on its compatibility with the actual geology of the subarea.},
  timestamp = {2015-10-26T18:53:49Z},
  number = {2},
  urldate = {2015-08-24},
  journal = {GEOPHYSICS},
  author = {{Silva}, J. and {Medeiros}, W. and {Barbosa}, V.},
  month = mar,
  year = {2001},
  pages = {511--520},
  file = {silva2001b.pdf:/home/leo/Dropbox/artigos/silva2001b.pdf:application/pdf}
}

@article{silva2014,
  title = {Fast gravity inversion of basement relief},
  volume = {79},
  issn = {0016-8033},
  doi = {10.1190/geo2014-0024.1},
  abstract = {Gravity interpretation of large sedimentary basins requires a large number of observations and of parameters estimations, so the development of very efficient gravity inversion methods applicable to such environments is of utmost importance. We found that the highly efficient Bott's method can be cast in the framework of Gauss-Newton's method for minimizing nonlinear functions. Also, we extended Bott's method to (1)~be applicable to sedimentary basins with density contrast between the sediments and the basement decreasing with depth according to different laws, (2)~optimize the modulus of the parameter correction vector, (3)~stabilize the solution by imposing that it be smooth, and (4)~quit the iteration according to an objective and effective criterion. To keep up the efficiency of Bott's method, stable solutions were obtained by applying a moving average to the usually unstable solution obtained at the last iteration. Solutions as efficacious as those obtained by the usual nonlinear method were produced by the present extension at a much smaller computation time. Nonlinear methods, with different implementations for solving a linear system of equations, required between one and two orders of magnitude more time to produce similar solutions using between 2000 and 3000 parameters and observations, for example.},
  timestamp = {2016-02-26T03:16:03Z},
  number = {5},
  urldate = {2014-09-15},
  journal = {Geophysics},
  author = {{Silva}, J. and {Santos}, D. and {Gomes}, K.},
  month = aug,
  year = {2014},
  pages = {G79--G91},
  file = {silva2014.pdf:/home/leo/Dropbox/artigos/silva2014.pdf:application/pdf}
}

@article{sun2014,
  title = {Adaptive {{Lp}} inversion for simultaneous recovery of both blocky and smooth features in a geophysical model},
  issn = {0956-540X, 1365-246X},
  doi = {10.1093/gji/ggu067},
  abstract = {Minimum-structure inversions using L2-norm measures have been widely applied to geophysical exploration problems. However, the smeared-out models resulting from L2-norm inversions are not always consistent with the real or expected geological structures, especially in regions where distinct interfaces between different rock units exist. To obtain sharp boundaries and blocky features, non-L2 inversions have been used successfully in geophysical imaging problems. In reality, however, both smooth and blocky features can be present in the subsurface physical properties or interfaces to be recovered. To deal with this situation, we develop a new method for adaptively recovering both smooth and blocky features in the constructed model from geophysical inversions. This method first detects different regions of the smoothness or blockiness in a model based on a sequence of inversions and then adaptively applies appropriate Lp model norm with different p values at different locations to complete the final inversion. We present two synthetic examples from basement inversion using gravity data and crosswell seismic traveltime tomography before demonstrating our method on a field data example at the U.S. Geological Survey Fractured Rock Research Site in central New Hampshire.},
  language = {en},
  timestamp = {2014-03-24T20:05:40Z},
  urldate = {2014-03-24},
  journal = {Geophysical Journal International},
  author = {{Sun}, Jiajia and {Li}, Yaoguo},
  month = mar,
  year = {2014},
  keywords = {Fractures and faults,Gravity anomalies and Earth structure,Inverse theory,Seismic tomography},
  pages = {ggu067},
  file = {sun2014.pdf:/home/leo/Dropbox/artigos/sun2014.pdf:application/pdf}
}

@article{uieda2016,
  title = {Tesseroids: forward modeling gravitational fields in spherical coordinates},
  timestamp = {2015-11-02T21:10:17Z},
  journal = {Geophysics},
  author = {{Uieda}, Leonardo and {Barbosa}, Valeria C. F. and {Braitenberg}, Carla},
  year = {2016},
  note = {In press (accepted)},
  file = {uieda2016.pdf:/home/leo/Dropbox/artigos/uieda2016.pdf:application/pdf}
}

@inproceedings{uieda2011c,
  title = {Optimal forward calculation method of the {{Marussi}} tensor due to a geologic structure at {{GOCE}} height},
  timestamp = {2015-10-26T18:53:49Z},
  urldate = {2013-08-09},
  booktitle = {Proceedings of the 4th {{International GOCE User Workshop}}},
  author = {{Uieda}, Leonardo and {Bomfim}, Everton P. and {Braitenberg}, Carla and {Molina}, Eder},
  year = {2011},
  file = {uieda2011c.pdf:/home/leo/Dropbox/artigos/uieda2011c.pdf:application/pdf}
}

@inproceedings{uieda2013a,
  title = {Modeling the {{Earth}} with {{Fatiando}} a {{Terra}}},
  timestamp = {2015-10-26T18:53:49Z},
  booktitle = {Proceedings of the 12th {{Python}} in {{Science Conference}}},
  author = {{Uieda}, Leonardo and {Oliveira Jr}, Vanderlei C. and {Barbosa}, Val{\'e}ria C. F.},
  editor = {{Walt}, St{\'e}fan van der and {Millman}, Jarrod and {Huff}, Katy},
  year = {2013},
  pages = {91 -- 98},
  file = {uieda2013a.pdf:/home/leo/Dropbox/artigos/uieda2013a.pdf:application/pdf}
}

@misc{uieda2015,
  title = {A tesserioid (spherical prism) in a geocentric coordinate system with a local-{{North}}-oriented coordinate system},
  timestamp = {2016-02-26T03:17:07Z},
  urldate = {2015-08-24},
  howpublished = {\url{http://dx.doi.org/10.6084/m9.figshare.1495525}},
  journal = {figshare},
  author = {{Uieda}, Leonardo},
  year = {2015},
  note = {Accessed 02-11-2015}
}

@article{vandermeijde2015,
  title = {Uncertainties in crustal thickness models for data sparse environments: {{A}} review for {{South America}} and {{Africa}}},
  volume = {84},
  issn = {0264-3707},
  shorttitle = {Uncertainties in crustal thickness models for data sparse environments},
  doi = {10.1016/j.jog.2014.09.013},
  abstract = {With the recently available high resolution gravity data from the GOCE satellite a whole range of crustal thickness models have been derived. The added value of GOCE is that it provides data globally, including regions that are poorly covered by seismological studies, like large parts of Africa and South America. Potentially these models can provide new insight in crustal structure for these data poor regions. We compare different models of crustal thickness for South America and Africa and attempt to assess the quality of different modelling techniques and the impact of different data sources. We introduce one new global crustal thickness model based on gravity data, DMM-1, and use seven additional, recently published, continental or global crustal thickness models based on gravity or seismological data. All models use different modelling techniques, and either gravity (four models) or seismological data (four models). We will show that significant differences exist between the models but that these cannot be directly related to the used data. Choices made in the selection and parametrization of the various modelling techniques have more impact than using different data sources including data sources of supposed higher quality. The significant differences, up to 28 km, between models can have a major influence on geodynamical analysis for the two continents. We propose that future work should focus on developing a standard for modelling in data sparse environments, and expanding seismological efforts in those regions that are most different between the shown models to verify the actual crustal thickness. Furthermore, the contribution and inclusion of (satellite) gravity data in crustal thickness models should be further explored.},
  timestamp = {2015-10-26T18:53:49Z},
  urldate = {2015-06-24},
  journal = {Journal of Geodynamics},
  author = {{van der Meijde}, M. and {Fadel}, I. and {Ditmar}, P. and {Hamayun}, M.},
  month = mar,
  year = {2015},
  keywords = {Data,Earth structure,GOCE,gravity,models},
  pages = {1--18},
  file = {vandermeijde2015.pdf:/home/leo/Dropbox/artigos/vandermeijde2015.pdf:application/pdf}
}

@article{vandermeijde2013,
  title = {Gravity derived {{Moho}} for {{South America}}},
  volume = {609},
  issn = {00401951},
  doi = {10.1016/j.tecto.2013.03.023},
  timestamp = {2016-02-26T03:18:49Z},
  urldate = {2013-08-21},
  journal = {Tectonophysics},
  author = {{van der Meijde}, M. and {Juli{\`a}}, J. and {Assump{\c c}{\~a}o}, M.},
  month = mar,
  year = {2013},
  pages = {456--467},
  file = {vandermeijde2013.pdf:/home/leo/Dropbox/artigos/vandermeijde2013.pdf:application/pdf}
}

@misc{waskom2015,
  title = {seaborn: v0.6.0},
  timestamp = {2016-02-26T03:20:08Z},
  howpublished = {\url{http://dx.doi.org/10.5281/zenodo.19108}},
  journal = {Zenodo},
  author = {{Waskom}, Michael and {Botvinnik}, Olga and {Hobson}, Paul and {Warmenhoven}, Jordi and {Cole}, John B. and {Halchenko}, Yaroslav and {Vanderplas}, Jake and {Hoyer}, Stephan and {Villalba}, Santi and {Quintero}, Eric and {Miles}, Alistair and {Augspurger}, Tom and {Yarkoni}, Tal and {Evans}, Constantine and {Wehner}, Daniel and {Rocher}, Luc and {Megies}, Tobias and {Coelho}, Luis Pedro and {Ziegler}, Erik and {Hoppe}, Travis and {Seabold}, Skipper and {Pascual}, Sergio and {Cloud}, Phillip and {Koskinen}, Miikka and {Hausler}, Chris and {kjemmett} and {Milajevs}, Dmitrijs and {Qalieh}, Adel and {Allan}, Dan and {Meyer}, Kyle},
  month = jun,
  year = {2015},
  note = {Accessed 02-11-2015}
}

@article{wieczorek1998,
  title = {Potential anomalies on a sphere: {{Applications}} to the thickness of the lunar crust},
  volume = {103},
  copyright = {Copyright 1998 by the American Geophysical Union.},
  issn = {2156-2202},
  shorttitle = {Potential anomalies on a sphere},
  doi = {10.1029/97JE03136},
  abstract = {A new technique for calculating potential anomalies on a sphere due to finite amplitude relief has been developed. We show that by raising the topography to the nth power and expanding this field into spherical harmonics, potential anomalies due to topography on spherical density interfaces can be computed to arbitrary precision. Using a filter for downward continuing the Bouguer anomaly, we have computed a variety of crustal thickness maps for the Moon, assuming both a homogeneous as well as a dual-layered crust. The crustal thickness maps for the homogeneous model give plausible results, but this model is not consistent with the seismic data, petrologic evidence, and geoid to topography ratios, all of which suggest some form of crustal stratification. Several dual-layered models were investigated, and it was found that only models with both upper and lower crustal thickness variations could satisfy the gravity and topography data. These models predict that the entire upper crust has been excavated beneath the major nearside multiring basins. Additionally, significant amounts of lower crustal material was excavated from these basins, especially beneath Crisium. This model also predicts that mantle material should not have been excavated during the South-Pole Aitken basin forming event, and that lower crustal material should be exposed at the surface in this basin.},
  language = {en},
  timestamp = {2015-05-11T17:12:33Z},
  number = {E1},
  urldate = {2015-05-11},
  journal = {Journal of Geophysical Research: Planets},
  author = {{Wieczorek}, Mark A. and {Phillips}, Roger J.},
  month = jan,
  year = {1998},
  keywords = {1214 Geopotential theory and determination},
  pages = {1715--1724},
  file = {wieczorek1998.pdf:/home/leo/Dropbox/artigos/wieczorek1998.pdf:application/pdf}
}

@article{wild-pfeiffer2008,
  title = {A comparison of different mass elements for use in gravity gradiometry},
  volume = {82},
  issn = {0949-7714, 1432-1394},
  doi = {10.1007/s00190-008-0219-8},
  timestamp = {2013-09-18T15:46:59Z},
  number = {10},
  urldate = {2013-09-18},
  journal = {Journal of Geodesy},
  author = {{Wild-Pfeiffer}, F.},
  month = apr,
  year = {2008},
  pages = {637--653},
  file = {wild-pfeiffer2008.pdf:/home/leo/Dropbox/artigos/wild-pfeiffer2008.pdf:application/pdf}
}


